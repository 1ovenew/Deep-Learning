我注意到  几乎所有机器学习从业人员(字幕来源：网易云课堂)
，都期望深刻理解偏差和方差
，这两个概念易学难精
，即使你自认为已经理解了方差和偏差的基本概念
，却总有一些意想不到的新东西出现
，关于深度学习的误差问题  另一个趋势是
，对偏差方差的权衡研究甚浅
，大家可能听说过这个概念
，但深度学习的误差很少权衡二者
，我们总是分别考虑偏差和方差
，却很少谈及偏差方差的权衡问题
，下面我们来一探究竟
，假设这就是数据集
，如果给这个数据集拟合一条直线  可能得到一个逻辑回归拟合
，但它并不能很好地拟合该数据集
，这是偏差高的情况
，我们称为“欠拟合”
，相反地
，如果我们拟合一个非常复杂的分类器
，比如深度神经网络或含有隐藏单元的神经网络
，可能就非常适用于这个数据集
，但是这看起来也不是一种很好的拟合方式
，分类器偏差较高  数据过度拟合
，在两者之间  可能还有一些像图中这样的
，复杂程度适中  数据拟合适度的分类器
，这个数据拟合看起来更加合理
，我们称之为“适度拟合”  是介于过拟合和欠拟合中间的一类
，在这样一个只有x1和x2两个特征的二维数据集中
，我们可以绘制数据  将偏差和方差可视化
，在多维空间数据中
，绘制数据和可视化分割边界无法实现
，但我们可以通过几个指标
，来研究偏差和方差
，我们沿用猫咪图片分类这个例子
，这张是猫咪图片  这张不是
，理解偏差和方差的两个关键数据是
，训练集误差和验证集误差
，为方便论证
，假设我们可以辨别图片中的小猫
，我们用肉眼识别几乎是不会出错的
，假定训练集错误率是1%
，为方便论证
，假设验证集错误率是11%
，可以看出  训练集设置得非常好
，而验证集设置相对较差
，我们可能过度拟合了训练集
，某种程度上  验证集并没有充分利用交叉验证集的作用
，像这种情况
，我们称之为“高偏差”
，通过查看训练集误差和验证集误差
，我们便可以诊断算法是否具有高偏差
，也就是说  衡量训练集和验证集误差
，得出不同结论
，假设训练集错误率是15%
，我把训练集错误率写在首行
，验证集错误率是16%
，假设该案例中人的错误率几乎为0%
，人们浏览这些图片  分辨出是不是猫
，算法并没有在训练集中得到很好训练
，如果训练数据的拟合度不高
，就是数据欠拟合
，就可以说这种算法偏差比较高
，相反  它对于验证集产生的结果却是合理的
，验证集中的错误率只比训练集的多了1%
，所以这种算法偏差高
，因为它甚至不能拟合训练集
，这与上一张幻灯片中最左边的图片相似
，再举一个例子
，训练集错误率是15%
，偏差相当高
，但是  验证集的评估结果更糟糕
，错误率达到30%
，这种情况下  我会认为这种算法偏差高
，因为它在训练集上结果不理想  方差也很高
，这是方差偏差都很糟糕的情况
，再看最后一个例子
，训练集错误率是0.5%  验证集错误率是1%
，用户看到这样的结果会很开心
，猫咪分类器只有1%的错误率  偏差和方差都很低
，有一点我先在这儿简单提一下
，具体的留到后面课程里讲
，这些分析都是基于假设预测的
，假设人眼辨别的错误率接近0%
，一般来说  最优误差也被称为基本误差
，所以  最优误差接近0%
，我就不在这里细讲了
，如果最优误差或基本误差非常高
，比如15%  我们再看看这个分类器
，15%的错误率对训练集来说也是非常合理的
，偏差不高  方差也非常低
，当所有分类器都不适用时
，如何分析偏差和方差呢
，比如  图片很模糊
，即使是人眼  或者没有系统可以准确无误地识别图片
，这种情况下  基本误差会更高
，那么分析过程就要做些改变了
，我们暂时先不讨论这些细微差别
，重点是通过查看训练集误差
，我们可以判断数据拟合情况  至少对于训练数据是这样
，可以判断是否有偏差问题
，然后查看错误率有多高
，当完成训练集训练  开始验证集验证时
，我们可以判断方差是否过高
，从训练集到验证集的这个过程中
，我们可以判断方差是否过高
，以上分析的前提都是假设基本误差很小
，训练集和验证集数据来自相同分布
，如果没有这些假设作为前提
，分析过程更更加复杂
，我们将会在稍后课程里讨论
，上一张幻灯片
，我们讲了高偏差和高方差的情况
，大家应该对优质分类器有了一定的认识
，偏差和方差都高是什么样子呢
，这种情况对于两个衡量标准来说都是非常糟糕的
，我们之前讲过  这样的分类器
，会产生高偏差
，因为它的数据拟合低
，像这种接近线性的分类器  数据拟合度低
，我用紫色线画出
，但如果我们稍微改变一下分类器
，它会过度拟合部分数据
，用紫色线画出的分类器具有高偏差和高方差
，偏差高是因为
，它几乎是一条线性分类器  并未拟合数据
，这种二次曲线能够很好地拟合数据
，这条曲线中间部分灵活性非常高
，却过度拟合了这两个样本
，这类分类器偏差很高  因为它几乎是线性的
，而采用曲线函数或二次元函数
，会产生高偏差
，因为它曲线灵活性太高  以致拟合了这两个错误样本
，和中间这些活跃数据
，这看起来有些不自然
，从两个维度上看都不太自然
，但对于高维数据
，有些数据区域偏差高  有些数据区域方差高
，所以在高维数据中采用这种分类器看起来就不会这么牵强了
，总结一下
，今天我们讲了如何通过分析训练集训练算法产生的误差
，和验证集验证算法产生的误差
，来诊断算法是否存在高偏差或高方差
，是否两个值都高  或者两个值都不高
，根据算法偏差和方差的具体情况
，决定接下来你要做的工作
，下节课  我会根据
，算法偏差和方差的高低情况
，讲解一些机器学习的基本方法
，帮助大家更系统地优化算法
，我们下节课见
，