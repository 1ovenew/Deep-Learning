1
00:00:00,280 --> 00:00:05,140
在上一个视频中 你已经看到了在超参数范围中(字幕来源：网易云课堂)
In the last video, you saw how sampling at
random, over the range of hyperparameters,

2
00:00:05,140 --> 00:00:09,330
随机取值可以提升你的搜索效率
can allow you to search over the space
of hyperparameters more efficiently.

3
00:00:09,330 --> 00:00:14,980
但随机取值并不是在有效值范围内的随机均匀取值
But it turns out that sampling at random
doesn't mean sampling uniformly at random,

4
00:00:14,980 --> 00:00:16,990


over the range of valid values.

5
00:00:16,990 --> 00:00:20,320
而是 选择合适的标尺
Instead, it's important to
pick the appropriate scale

6
00:00:20,320 --> 00:00:22,340
用于探究这些超参数 这很重要
on which to explore the hyperparamaters.

7
00:00:22,340 --> 00:00:25,700
在这个视频中 我会教你怎么做
In this video,
I want to show you how to do that.

8
00:00:25,700 --> 00:00:30,230
假设 你要选取隐藏单元的数量 n[l]
Let's say that you're trying to choose
the number of hidden units, n[l],
9
00:00:30,230 --> 00:00:31,250
对于给定层1而言
for a given layer l.

9
00:00:31,250 --> 00:00:36,310
假设 你选择的取值范围是从50到100中某点
And let's say that you think a good range
of values is somewhere from 50 to 100.

10
00:00:36,310 --> 00:00:41,110
这种情况下 看到这条从50-100的数轴
In that case, if you look at
the number line from 50 to 100,

11
00:00:41,110 --> 00:00:46,090
你可以随机在其上取点
maybe picking some number values
at random within this number line.

12
00:00:46,090 --> 00:00:50,500
这是一个搜索特定超参数的很直观的方式
There's a pretty visible way to search for
this particular hyperparameter.

13
00:00:50,500 --> 00:00:54,351
或者 如果你要选取神经网络的层数
Or if you're trying to decide on the
number of layers in your neural network,

14
00:00:54,351 --> 00:00:56,480
我们称之为字母L
we're calling that capital L.

15
00:00:56,480 --> 00:01:02,245
你也许会选择层数为2到4中的某个值
Maybe you think the total number of layers
should be somewhere between 2 to 4.

16
00:01:02,245 --> 00:01:08,030
接着 顺着2 3 4 随机均匀取样才比较合理
Then sampling uniformly at random,
along 2, 3 and 4, might be reasonable.

17
00:01:08,030 --> 00:01:11,920
你还可以应用网格搜索 你会觉得2 3 4
Or even using a grid search, where you
explicitly evaluate the values 2, 3 and 4

18
00:01:11,920 --> 00:01:15,340
这三个数值是合理的
might be reasonable.

19
00:01:15,340 --> 00:01:21,091
 这是几个在你的考虑范围内随机均匀取值的例子
So these were a couple examples where
sampling uniformly at random over the range you're contemplating,

20
00:01:21,091 --> 00:01:23,480
这些取值还蛮合理的
might be a reasonable thing to do.

21
00:01:23,480 --> 00:01:26,432
但这对某些超参数而言不适用
But this is not true for
all hyperparameters.

22
00:01:26,432 --> 00:01:28,850
看看这个例子
Let's look at another example.

23
00:01:28,850 --> 00:01:33,530
假设你在搜索超参数α 学习速率
Say your searching for the hyperparameter
alpha, the learning rate.

24
00:01:33,530 --> 00:01:38,000
假设你怀疑其值最小是0.0001
And let's say that you suspect
0.0001 might be on the low end,

25
00:01:38,000 --> 00:01:42,130
或最大是1
or maybe it could be as high as 1.

26
00:01:42,130 --> 00:01:48,451
如果你画一条从0.0001到1的数轴
Now if you draw the number
line from 0.0001 to 1,

27
00:01:48,451 --> 00:01:55,456
沿其随机均匀取值
and sample values uniformly at
random over this number line.

28
00:01:55,456 --> 00:02:02,219
那90%的数值将会落在0.1到1之间
Well about 90% of the values you
sample would be between 0.1 and 1.

29
00:02:02,219 --> 00:02:07,274
结果就是 在0.1到1之间 应用了90%的资源
So you're using 90% of the resources
to search between 0.1 and 1, and

30
00:02:07,274 --> 00:02:12,120
而在0.0001到0.1之间 只有10%的搜索资源
only 10% of the resources to
search between 0.0001 and 0.1.

31
00:02:12,120 --> 00:02:14,330
这看上去不太对
So that doesn't seem right.

32
00:02:14,330 --> 00:02:19,175
反而 用对数标尺搜索超参数的方式会更合理
Instead, it seems more reasonable to
search for hyperparameters on a log scale.

33
00:02:19,175 --> 00:02:23,437
因此这里不使用线性轴
Where instead of using a linear scale,

34
00:02:23,437 --> 00:02:30,377
分别依次取0.0001 0.001 0.01 1
you'd have 0.0001 here,and then 0.001, 0.01, 0.1, and then 1.

35
00:02:30,377 --> 00:02:37,360
在对数轴上均匀随机取点
And you instead sample uniformly, at
random, on this type of logarithmic scale.

36
00:02:37,360 --> 00:02:44,133
这样 在0.0001到0.001之间 就会有更多的搜索资源可用
Now you have more resources dedicated
to searching between 0.0001 and 0.001，

37
00:02:44,133 --> 00:02:50,270
还有在0.001到0.01之间等等
and between 0.001 and
0.01, and so on.

38
00:02:50,270 --> 00:02:53,950
所以 在Python中 你可以这样做
So in Python, the way you implement this,

39
00:02:55,780 --> 00:03:00,877
使r = -4 * np.random.rand()
is let r = -4 * np.random.rand().

40
00:03:00,877 --> 00:03:07,260
然后 α随机取值 α=10^r
And then a randomly chosen value of alpha,
would be alpha = 10 to the power of r.

41
00:03:08,350 --> 00:03:15,410
所以 第一行可以得出r∈[-4,0]
So after this first line, r will be
a random number between -4 and 0.

42
00:03:15,410 --> 00:03:20,505
那α会在10^（-4）和10^0之间
And so alpha here will be between
10 to the -4 and 10 to the 0.

43
00:03:20,505 --> 00:03:25,710
所以最左边的数字是10^（-4）
So 10 to the -4 is this left thing,
this 10 to the -4.

44
00:03:25,710 --> 00:03:28,320
最右边是10^0
And 1 is 10 to the 0.

45
00:03:28,320 --> 00:03:30,140
更常见的情况是
In a more general case,

46
00:03:30,140 --> 00:03:35,750
如果你在10^a和10^b之间取值
if you're trying to sample between 10 to
the a, to 10 to the b, on the log scale.

47
00:03:35,750 --> 00:03:40,700
在此例中 这是10^a
And in this example, this is 10 to the a.

48
00:03:40,700 --> 00:03:45,358
你可以通过log_10^0.0001算出a的值
And you can figure out what a is by
taking the log base 10 of 0.0001,

49
00:03:45,358 --> 00:03:49,170
即-4
which is going to tell you a is -4.

50
00:03:49,170 --> 00:03:51,430
在右边的值是10^b
And this value on the right,
this is 10 to the b.

51
00:03:51,430 --> 00:03:52,800
你可以算出b的值
And you can figure out what b is,

52
00:03:52,800 --> 00:03:56,655
log_10^1 即0
by taking log base 10 of 1,
which tells you b is equal to 0.

53
00:03:58,200 --> 00:04:04,353
你要做的 就是在【a,b】区间随机均匀地给r取值
So what you do, is then sample r
uniformly, at random, between a and b.

54
00:04:04,353 --> 00:04:06,857
这个例子中 r∈[-4,0]
So in this case,
r would be between -4 and 0.

55
00:04:06,857 --> 00:04:08,358
然后你可以设置α的值
And you can set alpha,

56
00:04:08,358 --> 00:04:14,000
基于随机取样的超参数值 α=10^r
on your randomly sampled hyperparameter
value, as 10 to the r, okay?

57
00:04:14,000 --> 00:04:16,210
所以 总结一下 在对数坐标上取值
So just to recap, to sample on
the log scale,

58
00:04:16,210 --> 00:04:20,252
取最小值的对数就得到a值
you take the low value,take logs to figure out what is a.

59
00:04:20,252 --> 00:04:23,911
取最大值的对数就得到b值
Take the high value,
take a log to figure out what is b.

60
00:04:23,911 --> 00:04:28,270
所以现在你在对数轴上的10^a到10^b区间取值
So now you're trying to sample,
from 10 to the a to the b, on a log scale.

61
00:04:28,270 --> 00:04:32,810
在a b间随意均匀的选取r值
So you set r uniformly,
at random, between a and b.

62
00:04:32,810 --> 00:04:35,850
将超参数设置为10^r
And then you set the hyperparameter
to be 10 to the r.

63
00:04:35,850 --> 00:04:40,070
这就是在对数轴上取值的过程
So that's how you implement
sampling on this logarithmic scale.

64
00:04:40,070 --> 00:04:46,010
最后 另一个棘手的例子是给β取值
Finally, one other tricky case is
sampling the hyperparameter beta,

65
00:04:46,010 --> 00:04:49,630
用于计算指数的加权平均值
used for computing exponentially weighted averages.

66
00:04:49,630 --> 00:04:55,800
假设你认为β是0.9到0.999之间的某个值
So let's say you suspect that beta should
be somewhere between 0.9 to 0.999.

67
00:04:55,800 --> 00:04:59,870
也许这就是你想搜索的范围
Maybe this is the range of
values you want to search over.

68
00:04:59,870 --> 00:05:03,440
请记住这一点 当计算指数的加权平均值时
So remember, that when computing
exponentially weighted averages,

69
00:05:03,440 --> 00:05:09,605
取0.9就像在10个值中计算平均值
using 0.9 is like averaging
over the last 10 values.

70
00:05:09,605 --> 00:05:13,304
有点类似于计算10天的温度平均值
kind of like taking the average
of 10 days temperature,

71
00:05:13,304 --> 00:05:18,403
而取0.999就是在1000个值中取平均
whereas using 0.999 is like averaging
over the last 1,000 values.

72
00:05:18,403 --> 00:05:21,434
所以 和上张幻灯片上的内容类似
So similar to what we saw on the last slide,

73
00:05:21,434 --> 00:05:28,558
如果你想在0.9到0.999区间搜索 那就不能用线性轴取值 对吧？
if you want to search between 0.9 and 0.999, it doesn't make sense to
sample on the linear scale, right?

74
00:05:28,558 --> 00:05:31,140
不要随机均匀在此区间取值
Uniformly, at random,
between 0.9 and 0.999.

75
00:05:31,140 --> 00:05:33,970
所以考虑这个问题最好的方法就是
So the best way to think about this,

76
00:05:33,970 --> 00:05:38,650
我们要探究的是1-β
is that we want to explore the range
of values for 1 minus beta,

77
00:05:38,650 --> 00:05:43,339
此值在 0.1到0.001区间内
which is going to now
range from 0.1 to 0.001.

78
00:05:43,339 --> 00:05:47,060
所以我们会给1-β取值
And so we'll sample the between beta,

79
00:05:47,060 --> 00:05:53,057
大概是从0.1到0.001
taking values from 0.1,
to maybe 0.1, to 0.001.

80
00:05:53,057 --> 00:05:57,739
应用之前幻灯片中介绍的方法
So using the method we have
figured out on the previous slide,

81
00:05:57,739 --> 00:06:01,532
这是10^(-1) 这是10^(-3)
this is 10 to the -1,
this is 10 to the -3.

82
00:06:01,532 --> 00:06:05,163
值得注意的是 在之前的幻灯片里 我们把把最小值写在左边
Notice on the previous slide,
we had the small value on the left, and

83
00:06:05,163 --> 00:06:08,182
最大值写在右边 但在这里 我们颠倒了大小
the large value on the right,
but here we have reversed.

84
00:06:08,182 --> 00:06:12,290
这里 左边的是最大值 右边的是最小值
We have the large value on the left,
and the small value on the right.

85
00:06:12,290 --> 00:06:19,870
所以你要做的就是在[-3,-1]里随机均匀的给r取值
So what you do, is you sample r uniformly,
at random, from -3 to -1.

86
00:06:19,870 --> 00:06:25,700
你设定了1-β=10^r 所以β=1-10^r
And you set 1- beta = 10 to the r,
and so beta = 1- 10 to the r.

87
00:06:25,700 --> 00:06:29,638
然后这就变成了你的超参数随机取值
And this becomes your randomly
sampled value of your hyperparameter,

88
00:06:29,638 --> 00:06:31,551
在特定的选择范围内
chosen on the appropriate scale.

89
00:06:31,551 --> 00:06:35,139
希望 用这种方式可以得到想要的结果
And hopefully this makes sense,
in that this way,

90
00:06:35,139 --> 00:06:39,979
你在0.9到0.99区间探究的资源
you spend as much resources
exploring the range 0.9 to 0.99,

91
00:06:39,979 --> 00:06:43,409
和在0.99到0.999区间探究的一样多
as you would exploring 0.99 to 0.999.

92
00:06:43,409 --> 00:06:47,699
所以 如果你想研究更多正式的数学证据
So if you want to study more formal
mathematical justification for why we're

93
00:06:47,699 --> 00:06:52,100
关于为什么我们要这样做 为什么用线性轴取值不是个好方法
doing this, right, why is it such a bad
idea to sample in a linear scale?

94
00:06:52,100 --> 00:06:56,120
这是因为当β接近1时
It is that, when beta is close to 1,

95
00:06:56,120 --> 00:07:02,230
所得结果的灵敏度会变化 即使β有微小的变化
the sensitivity of the results you get changes,
even with very small changes to beta.

96
00:07:02,230 --> 00:07:08,750
如果β在0.9到0.9005之间取值
So if beta goes from 0.9 to 0.9005,

97
00:07:08,750 --> 00:07:15,730
无关紧要 你的结果几乎不会变化
it's no big deal,
this is hardly any change in your results.

98
00:07:15,730 --> 00:07:19,720
但β值如果在0.999到0.9995之间
But if beta goes from 0.999 to 0.9995,

99
00:07:19,720 --> 00:07:26,615
这会对你的算法产生巨大影响 对吧？
this will have a huge impact on exactly
what your algorithm is doing, right?

100
00:07:26,615 --> 00:07:30,580
在这两种情况下 是根据大概10个值取平均
In both of these cases,
it's averaging over roughly 10 values.

101
00:07:30,580 --> 00:07:35,359
但这里 它是指数的加权平均值
But here it's gone from an exponentially
weighted average over

102
00:07:35,359 --> 00:07:40,790
基于1000个值 现在是2000个值
about the last 1,000 examples,
to now, the last 2,000 examples.

103
00:07:40,790 --> 00:07:44,460
因为这个公式1/（1-β）
And it's because that formula we have,
1 / 1- beta,

104
00:07:44,460 --> 00:07:49,140
当β接近1时 β就会对细微的变化变得很敏感
this is very sensitive to small changes
in beta, when beta is close to 1.

105
00:07:49,140 --> 00:07:52,059
所以 整个取值过程中
So what this whole sampling process does,

106
00:07:52,059 --> 00:07:57,426
你需要更加密集地取值 在β接近1的区间内
is it causes you to sample more densely
in the region of when beta is close to 1.

107
00:07:59,186 --> 00:08:03,480
或者说 当1-β接近于0时
Or, alternatively,
when 1- beta is close to 0.

108
00:08:03,480 --> 00:08:07,630
这样 你就可以更加有效的分布取样点
So that you can be more efficient in
terms of how you distribute the samples,

109
00:08:07,630 --> 00:08:11,430
更有效率的探究可能的结果
to explore the space of possible
outcomes more efficiently.

110
00:08:11,430 --> 00:08:14,250
希望能帮助你选择合适的标尺
So I hope this helps you select
the right scale on which to

111
00:08:14,250 --> 00:08:15,901
来给超参数取值
sample the hyperparameters.

112
00:08:15,901 --> 00:08:20,900
如果你没有在超参数选择中做出正确的标尺决定
In case you don't end up making the right
scaling decision on some hyperparameter choice,

113
00:08:20,900 --> 00:08:23,232
别担心
don't worry to much about it.

114
00:08:23,232 --> 00:08:24,720
即使你在均匀的标尺上取值
Even if you sample on the uniform scale,

115
00:08:24,720 --> 00:08:30,050
如果数值总量较多的话 你也会得到还不错的结果
where sum of the scale would have been superior,
you might still get okay results.

116
00:08:30,050 --> 00:08:33,830
尤其是应用从粗到细的搜索方法 在之后的迭代中
Especially if you use a coarse to fine
search, so that in later iterations,

117
00:08:33,830 --> 00:08:38,190
你还是会聚焦到有用的超参数取值的范围上
you focus in more on the most useful
range of hyperparameter values to sample.

118
00:08:38,190 --> 00:08:40,894
希望这会对你的超参数搜索有帮助
I hope this helps you in
your hyperparameter search.

119
00:08:40,894 --> 00:08:44,731
下一个视频中 我将会分享一些
In the next video, I also want to share
with you some thoughts of how to organize

120
00:08:44,731 --> 00:08:46,695
关于如何组建搜索过程的思考
your hyperparameter search process.

121
00:08:46,695 --> 00:08:49,570
希望它能使你的工作更高效
That I hope will make your
workflow a bit more efficient.

