WEBVTT
In the last video,you saw the basic beam search algorithm.
In this video, you learned some little changes that'll make it work even better.
Length normalization is a small change to the beam search algorithm
that can help you get much better results.
Here's what it is.
We talked about beam search as maximizing this probability.
And this product here is just expressing the observation that P of
y1 up to y Ty given x can
be expressed as P of y1 given x,times P of
y2 given x and y1 times dot dot dot,
up to I guess P of y, Ty given x, and
y1 up to y Ty minus one.
But then maybe this notation is a bit more scary, and
more intimidating than it needs to be.
But this is at product of probabilities that you see previously.
Now, rather than,now if you're implementing these,
these probabilities are all numbers less than 1.
In fact, often they are much less than 1.
And multiplying a lot of numbers less than 1 will result in a tiny, tiny,
tiny number,which can result in numerical underflow.
Meaning that is too small for
the probability part representation in your computer to store accurately.
So in practice, instead of maximizing this product, we will take logs.
And if you insert a log there, then a log of a product becomes a sum of a log and
maximizing this sum of log probabilities should give you the same
result in terms of selecting the most likely sentence y.
So by taking logs,you end up with a more numerically stable
algorithm that is less prone to rounding errors,
numerical rounding errors, or to really numerical underflow.
And because the log function,that's the log grouping function,
there's a strictly monotonically increasing function, maximizing P(y).
And because the logarithmic function,here's a long function,
is a strictly monotonically increasing function, we know that maximizing
log P(y) given x should give you the same result as maximizing P(y) given x,
as in the same value of y that maximizes this should also maximize that.
So in most implementations, you keep track of the,
sum of logs of probabilities, rather than the product of the probabilities.
Now, there is one other tweak to this.
All right, there's another typo here.
I hope you can do video editing magic.
So we can look good from the start.
Now there's one other change to this objective function
that makes the machine translation algorithm work even better.
Which is that if you refer to this original objective up here,
if you have a very long sentence, the probability of that sentence is going to
be low because you're multiplying as many terms here plus a numbers and
less than one to estimate the probability of that sentence.
And so if you multiply a lot of numbers that are less than one together,
you just tend to end up with a smaller probability.
And so this objective function has an undesirable effect,
that it maybe unnaturally tends to prefer very short translations,
tends to prefer very short outputs.
Because the probability of a short sentence is determined just by
multiplying fewer of these numbers less than one.
And so the product will just be not quite as small.
And by the way, the same thing is true for this.
The log of a probability is always less than or equal to 1.
You're actually in this major the lock, so
the more terms you had together, the more negative this thing becomes.
So there's one other change the algorithm that makes it work better,
which is instead of using this as the objective you're trying to maximize.
One thing you can do is normalize this by the number of words in your translation.
And so this takes the average of the log of the probability of each word and
this significantly reduces the penalty for outputting longer translations.
And in practice, as a heuristic,
instead of dividing by Ty, by the number of words in the output sentence.
Sometimes you use the softer approach,
where you have Ty to the power of alpha,where maybe alpha is equal to 0.7.
So if alpha was equal to 1, then you're completely normalizing by length.
If alpha was equal to 0 then well,Ty to the 0 would be 1,
then you're just not normalizing at all.
And this is somewhere in between full normalization and no normalization.
And alpha is another parameter,
alpha parameter of algorithm that you can tune to try to get the best of results.
And half of it using alpha this way,this is a heuristic or this is a hack,
there isn't a great theoretical justification for it but
people have found this works well.
People have found it works well in practice.
So many groups will do this.
And you can try out different values of alpha until, and
see which one gives you the best result.
So just to wrap up how you run beam search.
As you run beam search, you see a lot of sentences with length equal 1,
a lot of sentences with length equal 2,a lot of sentences with length
equals 3 and so on and maybe,you run beam search for 30 steps.
You consider output sentences up to length 30, let's say.
And so with beam width of 3,you'll be keeping track of the top three
possibilities for each of these possible sentence lengths.
1, 2, 3, 4, and so on up to 30.
Then you will look at all the, Output
sentences and score them against this score.
If you're using an EOS,you could also artificially tag on
the end of sentence token to your best three choices.
And so,you can take your top sentences and
just compute this objective function on the sentences that you have seen
through the beam search process.
And then finally, of all three sentences that you have added this way,
you will pick the one that achieves the highest value
on this normalized log probability objective.
Sometimes it's called a normalized likelihood objective.
And then that will be the final translation you output.
So that's how you implement beam search and
you get to play at this yourself in this week's program exercise.
Finally, a few implementational details.
How do you choose the beam width B?
The larger B is, the more possibilities you're considering, and
thus the better the sentence you probably find.
But the larger B is, the more computationally expensive your algorithm
is because you're also keeping a lot more possibilities around, right?
So finally,
let's just wrap up with some thoughts on how to choose the beam width B.
So here are the pros and cons of setting B to be very large versus very small.
If the B width is very large,then you consider a lot of possibilities.
And so you tend to get a better result
because you're considering a lot of different options, but it will be slower.
And the minimum requirements will also grow,
it'll also be computationally slower.
Whereas if you use a very small beam width, then you get a worse result.
Because you're just keeping less possibilities in mind
as the algorithm is running,but you get a result faster.
And the memory requirements will also be lower.
So in the previous video we use,in our running example,
a beam width of three so we're keeping three possibilities in mind.
In practice, that is on the small side.
In production systems, it's not uncommon to see a beam width maybe around ten.
And I think a beam width of 100 would be considered very large for
a production system,depending on the application.
But for research systems, where people want to squeeze out every last drop of
performance in order to publish a paper the best possible result.
It's not uncommon to see people use beam widths of 1,000 or 3,000.
But this is very application,as well as domain dependent.
So I would say, try out a variety of values of B and see what works for
your application.
But when B gets very large,there is often diminishing returns.
So for many applications, occasions,I will expect to see a huge gain as you go
from a beam width of 1, which is basically a beam search, to 3, to maybe 10.
But the gains as you go from 1,000 to 3,000 in beam width are might not
be as big and for
those of you that have taken maybe a lot of computer science courses before.
If you're familiar with computer science search algorithms like BFS,
Breadth-first search, or DFS, Depth-first search.
The way to think about beam search is that unlike those other algorithms,
which you might have learned about in a computer science algorithms course and
don't worry about it if you've not heard of these algorithms.
But if you've heard of Breadth-first search and Depth-first search,
then unlike those algorithms which are exact search algorithms,
beam search runs much faster but is not guaranteed to find the exact maximum for
this arg max that you'd like to find.
If you haven't heard of Breadth-first search or Depth-first search,
don't worry about it, it's not important for our purposes.
But if you have, this is how beam search release those algorithms.
So that's it for beam search which is a widely used algorithm in
many production system or in many commercial systems.
Now in the third course in the sequence of course of deep learning,
we talk a lot about error analysis.
It turns out, one of the most useful tools I found is to be able to do
error analysis on beam search.
So you sometimes wonder,should I increase my beam width?
Is my beam width working well enough?
And there's some simple things we can compute to give you
guidance on whether you need to work on improving your search algorithm.
Let's talk about that in the next video.