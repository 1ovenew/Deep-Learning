{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A lot of teams often find it exciting to surpasshuman-level performance on the specific recognitional classification task.Let's talk over some of the things you see if you try to accomplish this yourself.We've discussed before how machine learning progressgets harder as you approach or even surpass human-level performance.Let's talk over one more example of why that's the case.Let's say you have a problem where a team of humans discussing anddebating achieves 0.5% error,a single human 1% error,and you have an algorithm of 0.6% training error and 0.8% dev error.So in this case,what is the avoidable bias?So this one is relatively easier to answer,0.5% is your estimate of bayes error,so your avoidable bias is,you're not going to use this 1% number as reference,you can use this difference,so maybe you estimate your avoidable bias is at least 0.1%and your variance as 0.2%.So there's maybe more to do to reduce your variancethan your avoidable bias perhaps.But now let's take a harder example, let's say,a team of humans and single human performance, the same as before,but your algorithm gets 0.3% training error, and 0.4% dev error.Now, what is the avoidable bias?It's now actually much harder to answer that.Is the fact that your training error, 0.3%,does this mean you've over-fitted by 0.2%,or is bayes error, actually 0.1%,or maybe it's bayes error 0.2%,or maybe bayes error is 0.3%?You don't really know,but based on the information given in this example,you actually don't have enough informationto tell if you should focus on reducing bias or reducing variance in your algorithm.So that slows down the efficiency where you should make progress.Moreover, if your error is already better thaneven a team of humans looking at and discussing and debating the right label,for an example, then it's just also harder to rely on human intuition totell your algorithm what are ways thatyour algorithm could still improve the performance?So in this example,once you've surpassed this 0.5% threshold,your options, your ways of making progress onthe machine learning problem are just less clear.It doesn't mean you can't make progress,you might still be able to make significant progress,but some of the tools you have forpointing you in a clear direction just don't work as well.Now, there are many problems where machine learningsignificantly surpasses human-level performance.For example, I think,online advertising, estimating how likely someone is to click on that.Probably, learning algorithms do that much better today than any human could,or making product recommendations,recommending movies or books to you.I think that web sites today can do that much betterthan maybe even your closest friends can.All logistics predicting how long will take you to drive from A to Bor predicting how long to take a delivery vehicle to drive from A to B,or trying to predict whether someone will repay a loan,and therefore, whether or not you should approve a loan offer.All of these are problems where I thinktoday machine learning far surpasses a single human's performance.Notice something about these four examples.All four of these examples are actually learning from structured data,where you might have a database of what has users clicked on,database of products you bought before,databases of how long it takes to get from A to B,database of previous loan applications and their outcomes.And these are not natural perception problems,so these are not computer vision,or speech recognition, or natural language processing task.Humans tend to be very good in natural perception task.So it is possible,but it's just a bit harder for computers tosurpass human-level performance on natural perception task.And finally, all of these are problems where there areteams that have access to huge amounts of data.So for example, the best systems for all four of these applications have probablylooked at far more data of that application than any human could possibly look at.And so, that's also made it relatively easyfor a computer to surpass human-level performance.Now, the fact that there's so much data that computer could examine,so it can better find statistical patterns than even the human can not.Other than these problems,today there are speech recognition systems that can surpass human-level performance.And there are also some computer vision,some image recognition tasks,where computers have surpassed human-level performance.But because humans are very good at this natural perception task,I think it was harder for computers to get there.And then there are some medical tasks,for example, reading ECGs or diagnosing skin cancer,or certain narrow radiology task,where computers are getting really good andmaybe surpassing a single human-level performance.And I guess one of the exciting things aboutrecent advances in deep learning is that even for these taskswe can now surpass human-level performance in some cases,but it has been a bit harderbecause humans tend to be very good at this natural perception task.So surpassing human-level performance is often not easy,but given enough data there've been lots of deep learning systemshave surpassed human-level performance on a single supervisory problem.So that makes sense for an application you're working on.I hope that maybe someday you manage to getyour deep learning system to also surpass human-level performance.\n",
    "\n",
    "\n",
    "很多团队会因为 机器在特定的识别分类任务中(字幕来源：网易云课堂)，超越了人类水平而激动不已，我们谈谈这些情况 看看你们自己能不能达到，我们讨论过 机器学习进展，会在接近或者超越人类水平的时候变得越来越慢，我们举例谈谈为什么会这样，假设你有一个问题 一组人类专家充分讨论，辩论之后 达到0.5%的错误率，单个人类专家错误率是1%，然后你训练出来的算法有0.6%的训练错误率 0.6%的开发错误率，所以在这种情况下，可避免偏差是多少?，这个比较容易回答，0.5%是你对贝叶斯错误率的估计，所以可避免偏差就是，你不会用这个1%的数字作为参考，你用的是这个差值，所以也许你对可避免偏差的估计是至少0.1%，然后方程是0.2%，和减少可避免偏差比较起来，减少方差可能空间更大，但现在我们来看一个比较难的例子，一个人类专家团和单个人类专家的表现 和以前一样，但你的算法可以得到0.3%训练错误率 还有0.4%开发错误率，现在 可避免偏差是什么呢?，现在其实很难回答，事实上你的训练错误率是0.3%，这是否意味着你过拟合了0.2%，或者说贝叶斯错误率其实是 0.1%呢?，或者也许贝叶斯错误率是0.2%，或者贝叶斯错误率是0.3%呢?，你真的不知道，但是基于本例中给出的信息，你实际上没有足够的信息，来判断优化你的算法时应该专注减少偏差还是减少方差，这样你取得进展的效率就会降低，还有比如说 如果你的错误率已经比，一群充分讨论辩论后的人类专家更低，那么依靠人类直觉去，判断你的算法还能往什么方向优化，就很难了，所以在这个例子中，一旦你超过这个0.5%的门槛，要进一步优化你的机器学习问题，就没有明确的选项和前进的方向了，这并不意味着你不能取得进展，你仍然可以取得重大进展，但现有的一些工具，帮助你指明方向的工具就没那么好用了，现在 机器学习有很多问题，已经可以大大超越人类水平了，例如 我想，网络广告 估计某个用户点击广告的可能性，可能学习算法做到的水平已经超越任何人类了，还有提出产品建议，向你推荐电影或书籍之类的任务，我想今天的网站做到的水平，已经超越你最亲近的朋友了，还有物流预测 从A到B开车需要多久，或者预测快递车从A开到B需要多少时间，或者预测某人会不会偿还贷款，这样你就能判断是否批准这人的贷款，我想这些问题都是，今天的机器学习远远超过了单个人类的表现，请注意这四个例子，所有这四个例子都是从结构化数据中学习得来的，这里你可能有个数据库 记录用户点击的历史，你的购物历史数据库，或者从A到B需要多长时间的数据库，以前的贷款申请及结果的数据库，这些并不是自然感知问题，这些不是计算机视觉问题，或语音识别 或自然语言处理任务，人类在自然感知任务中往往表现非常好，所以有可能，对计算机来说，在自然感知任务的表现要超越人类要更难一些，最后 这些问题中 机器学习团队，都可以访问大量数据，所以比如说 那四个应用中 最好的系统看到的数据量，可能比任何人类能看到的都多，所以这样就相对容易，得到超越人类水平的系统，现在计算机可以检索那么多数据，它可以比人类更敏锐地识别出数据中的统计规律，除了这些问题，今天已经有语音识别系统超越人类水平了，还有一些计算机视觉任务，一些图像识别任务，计算机已经超越了人类水平，但是由于人类对这种自然感知任务非常擅长，我想计算机达到那种水平要难得多，还有一些医疗方面的任务，比如阅读ECG或诊断皮肤癌，或者某些特定领域的放射科读图任务，这些任务计算机做得非常好了，也许超越了单个人类的水平，在深度学习的最新进展中，其中一个振奋人心的方面是 即使在自然感知任务中，在某些情况下 计算机已经可以超越人类的水平了，不过现在肯定更加困难，因为人类一般很擅长这种自然感知任务，所以要达到超越人类的表现往往不容易，但如果有足够多的数据 已经有很多深度学习系统，在单一监督学习问题上已经超越了人类的水平，所以这对你在开发的应用是有意义的，我希望有一天你也能够搭建出，超越人类水平的深度学习系统，"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
