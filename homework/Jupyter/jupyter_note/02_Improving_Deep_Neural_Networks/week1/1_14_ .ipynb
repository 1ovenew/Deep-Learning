{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the last video you learned about gradient checking.In this video, I want to share with you some practical tips or some noteson how to actually go about implementing this for your neural network.First, don't use grad check in training, only to debug.So what I mean is that, computing d theta approx i, for all the values of i,this is a very slow computation.So to implement gradient descent, you'd use backprop to compute d theta andjust use backprop to compute the derivative.And it's only when you're debugging that you would compute thisto make sure it's close to d theta.But once you've done that, then you would turn off the grad check, anddon't run this during every iteration of gradient descent,because that's just much too slow.Second, if an algorithm fails grad check, look at the components,look at the individual components, and try to identify the bug.So what I mean by that is if d theta approx is very far from d theta,what I would do is look at the different values of i to see which are the values ofd theta approx that are really very different than the values of d theta.So for example,if you find that the values of theta or d theta, they're very far off,all correspond to dbl for some layer or for some layers,but the components for dw are quite close, right?Remember, different components of theta correspond to different components of b and w.When you find this is the case, then maybe you find that the bug isin how you're computing db, the derivative with respect to parameters b.And similarly, vice versa, if you find that the values that are very far,the values from d theta approx that are very far from d theta,you find all those components came from dw or from dw in a certain layer,then that might help you hone in on the location of the bug.This doesn't always let you identify the bug right away, butsometimes it helps you give you some guesses about where to track down the bug.Next, when doing grad check,remember your regularization term if you're using regularization.So if your cost function is J of theta equals 1 over m sum of yourlosses and then plus this regularization term, and sum of the l of wl squared,then this is the definition of J.And you should have that d theta is gradient of J with respect to theta,including this regularization term.So just remember to include that term.Next, grad check doesn't work with dropout,because in every iteration, dropout is randomly eliminating different subsets of the hidden units.There isn't an easy to compute cost function J that dropout is doing gradient descent on.It turns out that dropout can be viewed as optimizing some cost function J, butit's cost function J defined by summing over all exponentially largesubsets of nodes, they could eliminate in any iteration.So the cost function J is very difficult to compute,and you're just sampling the cost function,every time you eliminate different random subsets in those, we use dropout.So it's difficult to use grad check to double check your computation with dropouts.So what I usually do is implement grad check without dropout.So if you want, you can set keep-prob and dropout to be equal to 1.0.And then turn on dropout and hope that my implementation of dropout was correct.There are some other things you could do, like fix the pattern of nodes dropped andverify that grad check for that pattern of [INAUDIBLE] is correct,but in practice I don't usually do that.So my recommendation is turn off dropout, use grad check to double checkthat your algorithm is at least correct without dropout,and then turn on dropout.Finally, this is a subtlety.It is not impossible, rarely happens, but it's not impossible that yourimplementation of gradient descent is correct when w and b are close to 0,so at random initialization,But that as you run gradient descent and w and b become bigger,maybe your implementation of backprop is correct only when w and b is close to 0,but it gets more inaccurate when w and b become large.So one thing you could do, I don't do this very often,but one thing you could do is run grad check at random initializationand then train the network for a whileso that w and b have some time to wander away from 0,from your small random initial values.And then run grad check again after you've trained for some number of iterations.So that's it for gradient checking.And congratulations for coming to the end of this week's materials.In this week, you've learned about how to set up your train, dev, and test sets,how to analyze bias and varianceand what things to do if you have high bias versus high variance versusmaybe high bias and high variance.You also saw how to apply different forms of regularization, like L2 regularizationand dropout on your neural network.So some tricks for speeding up the training of your neural network.And then finally, gradient checking.So I think you've seen a lot in this week andyou get to exercise a lot of these ideas in this week's programming exercise.So best of luck with that, andI look forward to seeing you in the week two materials.\n",
    "\n",
    "上节课 我们讲了梯度检验(字幕来源：网易云课堂)，这节课 我想分享一些关于，如何在神经网络实施梯度检验的实用技巧和注意事项，首先 不要在训练中使用梯度检验 它只用于调试，我的意思是 计算所有i值的dθapprox[i]，是一个非常慢长的计算过程，为了实施梯度下降 你必须使用backprop来计算dθ，并使用backprop来计算导数，只有调试的时候 你才会计算它，来确认数值是否接近dθ，完成后 你会关闭梯度检验，梯度检验的每一个迭代过程都不执行它，因为它太慢了，第二点 如果算法的梯度检验失败 要检查所有项，检查每一项 并试着找出bug，也就是说 如果dθapprox[i]与dθ的值相差很大，我们要做的就是查找不同的i值 看看是哪个导致，dθapprox[i]与dθ的值相差这么多，举个例子，如果你发现 相对于某些层或某层的db[l]，θ或dθ的值相差很大，但是dw[l]的各项非常接近，注意 θ的各项与b和w的各项都是一一对应的，这时 你可能会发现，在计算参数b的导数db的过程中存在bug，反过来也一样  如果你发现它们的值相差很大，dθapprox的值与dθ相差很大，你会发现所有这些项都来自dw或某层的dw，可能帮你定位bug的位置，虽然未必能够帮你准确定位bug的位置，但它可以帮你估测需要在哪些地方追踪bug，第三点 在实施梯度检验时，如果使用正则化 请注意正则项，如果代价函数J等于，J(θ)=1/m ∑_i▒[L(y ̂^(i) ,y^(i))]+λ/2m ∑_l▒[||W^[l] ||]_F^2]，这就是代价函数J的定义，dθ等于与θ相关的J函数的梯度，包括这个正则项，记住一定要包括这个正则项，第四点 梯度检验不能与dropout同时使用，因为每次迭代过程中 dropout会随机消除隐层单元的不同子集，难以计算dropout在梯度下降上的代价函数J，因此dropout可作为优化代价函数J的一种方法，但是代价函数J被定义为对所有指数极大的节点子集求和，而在任何迭代过程中  这些节点都有可能被消除，所以很难计算代价函数J，你只是对成本函数做抽样，用dropout  每次随机消除不同的子集，所以很难用梯度检验来双重检验dropout的计算，所以我一般不同时使用梯度检验和dropout，如果你想这样做 可以把dropout中的keep.prob设置为1，然后打开dropout 并寄希望于dropout的实施是正确的，你还可以做点别的 比如修改节点丢失的模式，确认梯度检验是正确的，实际上 我一般不这么做，我建议关闭dropout 用梯度检验进行双重检查，在没有dropout的情况下 你的算法至少是正确的，然后打开dropout，最后一点 也是比较微妙的一点，现实中几乎不会出现这种情况，当W和b接近0时 梯度下降的实施是正确的，在随机初始化过程中...，但是在运行梯度下降时 W和b变得更大，可能只有在W和b接近0时 backprop的实施才是正确的，但是当W和b变大时 它会变得越来越不准确，你需要做一件事 我不经常这么做，就是在随机初始化过程中 运行梯度检验，然后再训练网络，W和b会有一段时间远离0，如果随机初始化值比较小，反复训练网络之后 再重新运行梯度检验，这就是梯度检验，恭喜大家 这是本周的最后一课了，回顾这一周 我们讲了如何配置训练集 验证集和测试集，如何分析偏差和方差，如何处理高偏差或高方差，以及高偏差和高方差并存的问题，如何在神经网络中应用不同形式的正则化 如L2正则化，和dropout，还有加快神经网络训练速度的技巧，最后是梯度检验，这一周我们学习了很多内容，你可以在本周的编码作业中多多练习这些概念，祝你好运，期待下周再见，"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
